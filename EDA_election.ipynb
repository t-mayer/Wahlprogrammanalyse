{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from docx import Document\n",
    "import numpy as np\n",
    "import collections\n",
    "import spacy\n",
    "import nltk\n",
    "from math import sqrt\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from spacy_sentiws import spaCySentiWS\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Stop words\n",
    "german_stop_words = stopwords.words('german')\n",
    "\n",
    "# German lemmatizer\n",
    "nlp = spacy.load(r'/home/tina/anaconda3/lib/python3.8/site-packages/de_core_news_sm/de_core_news_sm-2.3.0')\n",
    "\n",
    "# Sentiment analysis lexicon\n",
    "nlp2 = spacy.load('de')\n",
    "sentiws = spaCySentiWS(sentiws_path=r'/home/tina/anaconda3/lib/python3.8/site-packages/spacy_sentiws/data')\n",
    "nlp2.add_pipe(sentiws)\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert docx to dataframe.\n",
    "parties = ['fdp.docx', 'gruene.docx', 'spd.docx', 'linke.docx', 'afd.docx', 'cdu.docx']\n",
    "\n",
    "def text_to_df(party_list):\n",
    "    \n",
    "    # Collect texts in list.\n",
    "    df_list = []\n",
    "\n",
    "    for party in party_list:\n",
    "        doc = Document(party)\n",
    "        fullText = []\n",
    "        \n",
    "        # Join paragraphs.\n",
    "        for para in doc.paragraphs:\n",
    "            fullText.append(para.text)\n",
    "        full_doc = ' '.join(fullText)\n",
    "        df_list.append(full_doc)\n",
    "        \n",
    "    # Convert list to df.   \n",
    "    df = pd.DataFrame({'Text': df_list})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text       Party\n",
      "0    Nie gab es mehr zu tun Wie es ist, darf es n...         FDP\n",
      "1   DEUTSCHLAND. ALLES IST DRIN. Programmentwurf ...  Die Grünen\n",
      "2   DAS ZUKUNFTSPROGRAMM DER SPD –– WOFÜR WIR STE...         SPD\n",
      "3  Zeit zu handeln: Für soziale Sicherheit, Fried...       Linke\n",
      "4  Deutschland.Aber normal. Programm der Alternat...         AfD\n",
      "5  Das Programm für Stabilität und Erneuerung.  G...         CDU\n"
     ]
    }
   ],
   "source": [
    "df = text_to_df(parties)\n",
    "\n",
    "# Add parties column.\n",
    "df['Party'] = ['FDP', 'Die Grünen', 'SPD', 'Linke', 'AfD', 'CDU']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do some preliminary wrangling and cleaning.\n",
    "class DataCleaner:\n",
    "    def __init__(self, df_column):\n",
    "        self.df_column = df_column\n",
    "        \n",
    "    def remove_chars(self):\n",
    "        \n",
    "        # Remove white space and unnecessary characters.\n",
    "        column_stripped = self.df_column.strip()\n",
    "        return column_stripped\n",
    "    \n",
    "    def remove_punct(self):\n",
    "        \n",
    "        # Remove everything that is not whitespace or word character, dash or gender star.\n",
    "        no_punct = re.sub(r'[^\\w\\s*-]',' ',self.df_column) \n",
    "        \n",
    "        #Replace gender asterisk so it is seen as one word.\n",
    "        gendered = no_punct.replace('*innen', 'innen')\n",
    "        return gendered\n",
    "\n",
    "    def remove_digits(self):\n",
    "        \n",
    "        # Remove digits.\n",
    "        pattern = r'[0-9]'\n",
    "        no_digit = re.sub(pattern, '', self.df_column)\n",
    "        return no_digit\n",
    "        \n",
    "    def get_word_count(self):\n",
    "        \n",
    "        # Count how many words are in each text.\n",
    "        word_count = len(self.df_column.split())\n",
    "        return word_count\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove digits, whitespace, unnecessary characters\n",
    "df['Text'] = df['Text'].apply(lambda row: DataCleaner(str(row)).remove_chars())\n",
    "df['Text'] = df['Text'].apply(lambda row: DataCleaner(row).remove_punct())\n",
    "df['Text'] = df['Text'].apply(lambda row: DataCleaner(row).remove_digits())\n",
    "\n",
    "# Count words\n",
    "df['Word count'] = df['Text'].apply(lambda row: DataCleaner(row).get_word_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Party</th>\n",
       "      <th>Word count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nie gab es mehr zu tun Wie es ist  darf es nic...</td>\n",
       "      <td>FDP</td>\n",
       "      <td>29405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEUTSCHLAND  ALLES IST DRIN  Programmentwurf z...</td>\n",
       "      <td>Die Grünen</td>\n",
       "      <td>47794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAS ZUKUNFTSPROGRAMM DER SPD    WOFÜR WIR STEH...</td>\n",
       "      <td>SPD</td>\n",
       "      <td>23428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zeit zu handeln  Für soziale Sicherheit  Fried...</td>\n",
       "      <td>Linke</td>\n",
       "      <td>53162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deutschland Aber normal  Programm der Alternat...</td>\n",
       "      <td>AfD</td>\n",
       "      <td>23415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Das Programm für Stabilität und Erneuerung   G...</td>\n",
       "      <td>CDU</td>\n",
       "      <td>44402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text       Party  Word count\n",
       "0  Nie gab es mehr zu tun Wie es ist  darf es nic...         FDP       29405\n",
       "1  DEUTSCHLAND  ALLES IST DRIN  Programmentwurf z...  Die Grünen       47794\n",
       "2  DAS ZUKUNFTSPROGRAMM DER SPD    WOFÜR WIR STEH...         SPD       23428\n",
       "3  Zeit zu handeln  Für soziale Sicherheit  Fried...       Linke       53162\n",
       "4  Deutschland Aber normal  Programm der Alternat...         AfD       23415\n",
       "5  Das Programm für Stabilität und Erneuerung   G...         CDU       44402"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PrepareText splits text into tokens, lemmas, removes stopwords, and creates bow\n",
    "\n",
    "class PrepareText:\n",
    "    def __init__(self, df_column):\n",
    "        self.df_column = df_column\n",
    "        \n",
    "    def remove_stopwords(self):\n",
    "        token = self.df_column.split(' ')\n",
    "        no_stopwords = [word for word in token if word.lower() not in german_stop_words]\n",
    "        \n",
    "        # remove whitespace\n",
    "        no_stopwords = [word for word in no_stopwords if word]\n",
    "\n",
    "        return no_stopwords\n",
    "        \n",
    "    def get_lemmas(self):\n",
    "        \n",
    "        # create list for lemmas\n",
    "        lemmas_list = []\n",
    "        \n",
    "        # extract lemmas based on spacy\n",
    "        for sentence in self.df_column:\n",
    "            doc = nlp(sentence)\n",
    "            for token in doc:\n",
    "                lemmas_list.append(token.lemma_)\n",
    "                \n",
    "        return lemmas_list\n",
    "    \n",
    "    def get_bow(self):\n",
    "        \n",
    "        # Use lemmas to create bow dict.\n",
    "        lemmas = self.df_column\n",
    "        \n",
    "        # Bow: counts word occurences, and \n",
    "        # returns ordered dictionary beginning with the most common\n",
    "        bow = OrderedDict(Counter(lemmas).most_common())\n",
    "        return bow\n",
    "    \n",
    "    def get_pos_bow(self):\n",
    "        \n",
    "        # Pos tags list\n",
    "        pos_tags = []\n",
    "        \n",
    "        # Extract pos tags based on spacy\n",
    "        doc = nlp(self.df_column)\n",
    "        for token in doc:\n",
    "            pos_tags.append(token.pos_)\n",
    "                \n",
    "        # Create Pos tags dictionary    \n",
    "        pos_bow = OrderedDict(Counter(pos_tags).most_common())\n",
    "        return pos_bow\n",
    "    \n",
    "    def get_pos_dict(self):\n",
    "        \n",
    "        # Pos tags dict\n",
    "        pos_tags_list = []\n",
    "                \n",
    "        # Get Pos tags with the words.\n",
    "        doc = nlp(self.df_column)\n",
    "        for token in doc:\n",
    "            pos_tags_list.append((token.pos_,token.text))\n",
    "            \n",
    "        # Create Pos-word dictionary    \n",
    "        pos_words_bow = OrderedDict(Counter(pos_tags_list).most_common())\n",
    "        return pos_words_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords: Apply row-wise for each text.\n",
    "df['Text: No Stopwords'] = df['Text'].apply(lambda row: PrepareText(row).remove_stopwords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize text without stopwords.\n",
    "df['Lemmas'] = df['Text: No Stopwords'].apply(lambda row: PrepareText(row).get_lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bag of words of text without stopwords.\n",
    "df['BoW'] = df['Text: No Stopwords'].apply(lambda row: PrepareText(row).get_bow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bag of words of pos.\n",
    "df['Pos BoW'] = df['Text'].apply(lambda row: PrepareText(row).get_pos_bow())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dict of words and their pos.\n",
    "df['Pos Word Dict'] = df['Text'].apply(lambda row: PrepareText(row).get_pos_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Party</th>\n",
       "      <th>Word count</th>\n",
       "      <th>Text: No Stopwords</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>BoW</th>\n",
       "      <th>Pos BoW</th>\n",
       "      <th>Pos Word Dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nie gab es mehr zu tun Wie es ist  darf es nic...</td>\n",
       "      <td>FDP</td>\n",
       "      <td>29405</td>\n",
       "      <td>[Nie, gab, mehr, tun, darf, bleiben, darf, ble...</td>\n",
       "      <td>[Nie, geben, mehr, tun, dürfen, bleiben, dürfe...</td>\n",
       "      <td>{'Freie': 346, 'Demokraten': 342, 'fordern': 9...</td>\n",
       "      <td>{'NOUN': 7849, 'DET': 4089, 'ADJ': 3916, 'VERB...</td>\n",
       "      <td>{('SPACE', ' '): 3218, ('CCONJ', 'und'): 1388,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEUTSCHLAND  ALLES IST DRIN  Programmentwurf z...</td>\n",
       "      <td>Die Grünen</td>\n",
       "      <td>47794</td>\n",
       "      <td>[DEUTSCHLAND, DRIN, Programmentwurf, Bundestag...</td>\n",
       "      <td>[DEUTSCHLAND, DRIN, Programmentwurf, Bundestag...</td>\n",
       "      <td>{'mehr': 163, 'Menschen': 156, 'sollen': 126, ...</td>\n",
       "      <td>{'NOUN': 11735, 'DET': 6316, 'SPACE': 5965, 'A...</td>\n",
       "      <td>{('SPACE', ' '): 5585, ('CCONJ', 'und'): 2437,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAS ZUKUNFTSPROGRAMM DER SPD    WOFÜR WIR STEH...</td>\n",
       "      <td>SPD</td>\n",
       "      <td>23428</td>\n",
       "      <td>[ZUKUNFTSPROGRAMM, SPD, WOFÜR, STEHEN, ANTREIB...</td>\n",
       "      <td>[ZUKUNFTSPROGRAMM, SPD, WOFÜR, STEHEN, ANTREIB...</td>\n",
       "      <td>{'müssen': 73, 'mehr': 66, 'dafür': 53, 'unter...</td>\n",
       "      <td>{'NOUN': 5891, 'DET': 3417, 'SPACE': 2985, 'AD...</td>\n",
       "      <td>{('SPACE', ' '): 2537, ('CCONJ', 'und'): 1197,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zeit zu handeln  Für soziale Sicherheit  Fried...</td>\n",
       "      <td>Linke</td>\n",
       "      <td>53162</td>\n",
       "      <td>[Zeit, handeln, soziale, Sicherheit, Frieden, ...</td>\n",
       "      <td>[Zeit, handeln, soziale, Sicherheit, Friede, K...</td>\n",
       "      <td>{'müssen': 391, 'Menschen': 219, 'mehr': 170, ...</td>\n",
       "      <td>{'NOUN': 14246, 'SPACE': 7760, 'DET': 7273, 'V...</td>\n",
       "      <td>{('SPACE', ' '): 6729, ('CCONJ', 'und'): 2707,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deutschland Aber normal  Programm der Alternat...</td>\n",
       "      <td>AfD</td>\n",
       "      <td>23415</td>\n",
       "      <td>[Deutschland, normal, Programm, Alternative, D...</td>\n",
       "      <td>[Deutschland, normal, Programm, Alternative, D...</td>\n",
       "      <td>{'AfD': 152, 'Deutschland': 93, 'deutschen': 5...</td>\n",
       "      <td>{'NOUN': 6344, 'DET': 3826, 'SPACE': 3158, 'AD...</td>\n",
       "      <td>{('SPACE', ' '): 2493, ('CCONJ', 'und'): 950, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Das Programm für Stabilität und Erneuerung   G...</td>\n",
       "      <td>CDU</td>\n",
       "      <td>44402</td>\n",
       "      <td>[Programm, Stabilität, Erneuerung, GEMEINSAM, ...</td>\n",
       "      <td>[Programm, Stabilität, Erneuerung, GEMEINSAM, ...</td>\n",
       "      <td>{'Deutschland': 148, 'mehr': 139, 'müssen': 13...</td>\n",
       "      <td>{'NOUN': 10430, 'SPACE': 8254, 'DET': 5863, 'A...</td>\n",
       "      <td>{('SPACE', ' '): 6132, ('CCONJ', 'und'): 2360,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text       Party  Word count  \\\n",
       "0  Nie gab es mehr zu tun Wie es ist  darf es nic...         FDP       29405   \n",
       "1  DEUTSCHLAND  ALLES IST DRIN  Programmentwurf z...  Die Grünen       47794   \n",
       "2  DAS ZUKUNFTSPROGRAMM DER SPD    WOFÜR WIR STEH...         SPD       23428   \n",
       "3  Zeit zu handeln  Für soziale Sicherheit  Fried...       Linke       53162   \n",
       "4  Deutschland Aber normal  Programm der Alternat...         AfD       23415   \n",
       "5  Das Programm für Stabilität und Erneuerung   G...         CDU       44402   \n",
       "\n",
       "                                  Text: No Stopwords  \\\n",
       "0  [Nie, gab, mehr, tun, darf, bleiben, darf, ble...   \n",
       "1  [DEUTSCHLAND, DRIN, Programmentwurf, Bundestag...   \n",
       "2  [ZUKUNFTSPROGRAMM, SPD, WOFÜR, STEHEN, ANTREIB...   \n",
       "3  [Zeit, handeln, soziale, Sicherheit, Frieden, ...   \n",
       "4  [Deutschland, normal, Programm, Alternative, D...   \n",
       "5  [Programm, Stabilität, Erneuerung, GEMEINSAM, ...   \n",
       "\n",
       "                                              Lemmas  \\\n",
       "0  [Nie, geben, mehr, tun, dürfen, bleiben, dürfe...   \n",
       "1  [DEUTSCHLAND, DRIN, Programmentwurf, Bundestag...   \n",
       "2  [ZUKUNFTSPROGRAMM, SPD, WOFÜR, STEHEN, ANTREIB...   \n",
       "3  [Zeit, handeln, soziale, Sicherheit, Friede, K...   \n",
       "4  [Deutschland, normal, Programm, Alternative, D...   \n",
       "5  [Programm, Stabilität, Erneuerung, GEMEINSAM, ...   \n",
       "\n",
       "                                                 BoW  \\\n",
       "0  {'Freie': 346, 'Demokraten': 342, 'fordern': 9...   \n",
       "1  {'mehr': 163, 'Menschen': 156, 'sollen': 126, ...   \n",
       "2  {'müssen': 73, 'mehr': 66, 'dafür': 53, 'unter...   \n",
       "3  {'müssen': 391, 'Menschen': 219, 'mehr': 170, ...   \n",
       "4  {'AfD': 152, 'Deutschland': 93, 'deutschen': 5...   \n",
       "5  {'Deutschland': 148, 'mehr': 139, 'müssen': 13...   \n",
       "\n",
       "                                             Pos BoW  \\\n",
       "0  {'NOUN': 7849, 'DET': 4089, 'ADJ': 3916, 'VERB...   \n",
       "1  {'NOUN': 11735, 'DET': 6316, 'SPACE': 5965, 'A...   \n",
       "2  {'NOUN': 5891, 'DET': 3417, 'SPACE': 2985, 'AD...   \n",
       "3  {'NOUN': 14246, 'SPACE': 7760, 'DET': 7273, 'V...   \n",
       "4  {'NOUN': 6344, 'DET': 3826, 'SPACE': 3158, 'AD...   \n",
       "5  {'NOUN': 10430, 'SPACE': 8254, 'DET': 5863, 'A...   \n",
       "\n",
       "                                       Pos Word Dict  \n",
       "0  {('SPACE', ' '): 3218, ('CCONJ', 'und'): 1388,...  \n",
       "1  {('SPACE', ' '): 5585, ('CCONJ', 'und'): 2437,...  \n",
       "2  {('SPACE', ' '): 2537, ('CCONJ', 'und'): 1197,...  \n",
       "3  {('SPACE', ' '): 6729, ('CCONJ', 'und'): 2707,...  \n",
       "4  {('SPACE', ' '): 2493, ('CCONJ', 'und'): 950, ...  \n",
       "5  {('SPACE', ' '): 6132, ('CCONJ', 'und'): 2360,...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word use: Who talks the most about what? How do parties use language?\n",
    "\n",
    "class MostCommon():\n",
    "    \n",
    "    def __init__(self, df_column):\n",
    "        self.df_column = df_column\n",
    "    \n",
    "    # Most common words.\n",
    "    def most_common_words(self):\n",
    "        most_common_ten = list(self.df_column.items())[:10]\n",
    "        return dict(most_common_ten)   \n",
    "        \n",
    "    def most_common_pos_tags(self):\n",
    "        \n",
    "        most_common_pos = {}\n",
    "        \n",
    "        # Get the top 10 most used POS tags.\n",
    "        for key, value in self.df_column.items():\n",
    "            if len(most_common_pos) < 10:\n",
    "                if key != 'SPACE':\n",
    "                    most_common_pos[key] = value\n",
    "        return most_common_pos\n",
    "        \n",
    "    def get_most_common_nouns(self):\n",
    "        \n",
    "        most_common_nouns = {}\n",
    "        \n",
    "        for key, value in self.df_column.items():\n",
    "            if len(most_common_nouns) < 10:\n",
    "                if 'NOUN' in key:\n",
    "                    most_common_nouns[key[1]] = value\n",
    "        return most_common_nouns\n",
    "       \n",
    "        \n",
    "    def get_most_common_verbs(self):\n",
    "        \n",
    "        most_common_verbs = {}\n",
    "        \n",
    "        for key, value in self.df_column.items():\n",
    "            if len(most_common_verbs) < 10:\n",
    "                if 'VERB' in key:\n",
    "                    most_common_verbs[key[1]] = value\n",
    "        return most_common_verbs\n",
    "        \n",
    "    def get_most_common_adjectives(self):\n",
    "                \n",
    "        most_common_adj = {}\n",
    "        \n",
    "        for key, value in self.df_column.items():\n",
    "            if len(most_common_adj) < 10:\n",
    "                if 'ADJ' in key:\n",
    "                    most_common_adj[key[1]] = value\n",
    "        return most_common_adj\n",
    "\n",
    "    def most_common_bigrams(self):\n",
    "                \n",
    "        # Get the bigrams from text string.\n",
    "        nltk_tokens = nltk.word_tokenize(self.df_column)\n",
    "        bigrams = nltk.bigrams(nltk_tokens)\n",
    "        \n",
    "        bigrams_dict = OrderedDict(Counter(bigrams).most_common())\n",
    "        bigrams_list = list(bigrams_dict.items())[:10]\n",
    "        bigrams_dict = dict([(' '.join(x[0]), x[1]) for x in bigrams_list])\n",
    "        return bigrams_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most common...\n",
    "df['Most common words'] = df['BoW'].apply(lambda row: MostCommon(row).most_common_words())\n",
    "df['Most common POS tags'] = df['Pos BoW'].apply(lambda row: MostCommon(row).most_common_pos_tags())\n",
    "df['Most common nouns'] = df['Pos Word Dict'].apply(lambda row: MostCommon(row).get_most_common_nouns())\n",
    "df['Most common verbs'] = df['Pos Word Dict'].apply(lambda row: MostCommon(row).get_most_common_verbs())\n",
    "df['Most common adj'] = df['Pos Word Dict'].apply(lambda row: MostCommon(row).get_most_common_adjectives())\n",
    "df['Most common bigrams'] = df['Text'].apply(lambda row: MostCommon(row).most_common_bigrams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not needed.\n",
    "df_new = df.drop(['Text', 'Text: No Stopwords','Lemmas', 'Pos Word Dict', 'Pos BoW', 'BoW'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Word count</th>\n",
       "      <th>Most common words</th>\n",
       "      <th>Most common POS tags</th>\n",
       "      <th>Most common nouns</th>\n",
       "      <th>Most common verbs</th>\n",
       "      <th>Most common adj</th>\n",
       "      <th>Most common bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDP</td>\n",
       "      <td>29405</td>\n",
       "      <td>{'Freie': 346, 'Demokraten': 342, 'fordern': 9...</td>\n",
       "      <td>{'NOUN': 7849, 'DET': 4089, 'ADJ': 3916, 'VERB...</td>\n",
       "      <td>{'Demokraten': 342, 'Menschen': 61, 'Unternehm...</td>\n",
       "      <td>{'wollen': 434, 'muss': 113, 'fordern': 99, 'm...</td>\n",
       "      <td>{'Freie': 346, 'europäischen': 32, 'neue': 30,...</td>\n",
       "      <td>{'Freie Demokraten': 340, 'Wir Freie': 329, 'D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Die Grünen</td>\n",
       "      <td>47794</td>\n",
       "      <td>{'mehr': 163, 'Menschen': 156, 'sollen': 126, ...</td>\n",
       "      <td>{'NOUN': 11735, 'DET': 6316, 'ADJ': 5912, 'VER...</td>\n",
       "      <td>{'Menschen': 156, 'Unternehmen': 60, 'Frauen':...</td>\n",
       "      <td>{'wollen': 489, 'können': 170, 'sollen': 126, ...</td>\n",
       "      <td>{'neue': 67, 'europäische': 43, 'europäischen'...</td>\n",
       "      <td>{'wollen wir': 279, 'Wir wollen': 175, 'in der...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPD</td>\n",
       "      <td>23428</td>\n",
       "      <td>{'müssen': 73, 'mehr': 66, 'dafür': 53, 'unter...</td>\n",
       "      <td>{'NOUN': 5891, 'DET': 3417, 'ADJ': 2908, 'ADP'...</td>\n",
       "      <td>{'Menschen': 50, 'Arbeit': 44, 'Gesellschaft':...</td>\n",
       "      <td>{'wollen': 104, 'müssen': 73, 'können': 63, 'u...</td>\n",
       "      <td>{'neue': 36, 'neuen': 22, 'digitalen': 21, 'so...</td>\n",
       "      <td>{'Wir werden': 167, 'werden wir': 159, 'und di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linke</td>\n",
       "      <td>53162</td>\n",
       "      <td>{'müssen': 391, 'Menschen': 219, 'mehr': 170, ...</td>\n",
       "      <td>{'NOUN': 14246, 'DET': 7273, 'VERB': 6726, 'AD...</td>\n",
       "      <td>{'Menschen': 219, 'Beschäftigten': 97, 'Arbeit...</td>\n",
       "      <td>{'wollen': 583, 'müssen': 391, 'muss': 254, 'k...</td>\n",
       "      <td>{'soziale': 91, 'öffentlichen': 79, 'gute': 74...</td>\n",
       "      <td>{'Wir wollen': 318, 'wollen wir': 246, 'in der...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AfD</td>\n",
       "      <td>23415</td>\n",
       "      <td>{'AfD': 152, 'Deutschland': 93, 'deutschen': 5...</td>\n",
       "      <td>{'NOUN': 6344, 'DET': 3826, 'ADJ': 2980, 'ADP'...</td>\n",
       "      <td>{'Bürger': 31, 'Familien': 30, 'Kinder': 27, '...</td>\n",
       "      <td>{'muss': 81, 'wollen': 69, 'müssen': 54, 'ford...</td>\n",
       "      <td>{'deutschen': 54, 'deutsche': 24, 'europäische...</td>\n",
       "      <td>{'Die AfD': 107, 'in der': 58, 'für die': 57, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CDU</td>\n",
       "      <td>44402</td>\n",
       "      <td>{'Deutschland': 148, 'mehr': 139, 'müssen': 13...</td>\n",
       "      <td>{'NOUN': 10430, 'DET': 5863, 'ADJ': 5482, 'VER...</td>\n",
       "      <td>{'Menschen': 111, 'Sicherheit': 67, 'Land': 61...</td>\n",
       "      <td>{'wollen': 483, 'können': 174, 'müssen': 138, ...</td>\n",
       "      <td>{'neue': 78, 'digitale': 50, 'stärker': 50, 'b...</td>\n",
       "      <td>{'Wir wollen': 266, 'Wir werden': 203, 'wollen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Party  Word count                                  Most common words  \\\n",
       "0         FDP       29405  {'Freie': 346, 'Demokraten': 342, 'fordern': 9...   \n",
       "1  Die Grünen       47794  {'mehr': 163, 'Menschen': 156, 'sollen': 126, ...   \n",
       "2         SPD       23428  {'müssen': 73, 'mehr': 66, 'dafür': 53, 'unter...   \n",
       "3       Linke       53162  {'müssen': 391, 'Menschen': 219, 'mehr': 170, ...   \n",
       "4         AfD       23415  {'AfD': 152, 'Deutschland': 93, 'deutschen': 5...   \n",
       "5         CDU       44402  {'Deutschland': 148, 'mehr': 139, 'müssen': 13...   \n",
       "\n",
       "                                Most common POS tags  \\\n",
       "0  {'NOUN': 7849, 'DET': 4089, 'ADJ': 3916, 'VERB...   \n",
       "1  {'NOUN': 11735, 'DET': 6316, 'ADJ': 5912, 'VER...   \n",
       "2  {'NOUN': 5891, 'DET': 3417, 'ADJ': 2908, 'ADP'...   \n",
       "3  {'NOUN': 14246, 'DET': 7273, 'VERB': 6726, 'AD...   \n",
       "4  {'NOUN': 6344, 'DET': 3826, 'ADJ': 2980, 'ADP'...   \n",
       "5  {'NOUN': 10430, 'DET': 5863, 'ADJ': 5482, 'VER...   \n",
       "\n",
       "                                   Most common nouns  \\\n",
       "0  {'Demokraten': 342, 'Menschen': 61, 'Unternehm...   \n",
       "1  {'Menschen': 156, 'Unternehmen': 60, 'Frauen':...   \n",
       "2  {'Menschen': 50, 'Arbeit': 44, 'Gesellschaft':...   \n",
       "3  {'Menschen': 219, 'Beschäftigten': 97, 'Arbeit...   \n",
       "4  {'Bürger': 31, 'Familien': 30, 'Kinder': 27, '...   \n",
       "5  {'Menschen': 111, 'Sicherheit': 67, 'Land': 61...   \n",
       "\n",
       "                                   Most common verbs  \\\n",
       "0  {'wollen': 434, 'muss': 113, 'fordern': 99, 'm...   \n",
       "1  {'wollen': 489, 'können': 170, 'sollen': 126, ...   \n",
       "2  {'wollen': 104, 'müssen': 73, 'können': 63, 'u...   \n",
       "3  {'wollen': 583, 'müssen': 391, 'muss': 254, 'k...   \n",
       "4  {'muss': 81, 'wollen': 69, 'müssen': 54, 'ford...   \n",
       "5  {'wollen': 483, 'können': 174, 'müssen': 138, ...   \n",
       "\n",
       "                                     Most common adj  \\\n",
       "0  {'Freie': 346, 'europäischen': 32, 'neue': 30,...   \n",
       "1  {'neue': 67, 'europäische': 43, 'europäischen'...   \n",
       "2  {'neue': 36, 'neuen': 22, 'digitalen': 21, 'so...   \n",
       "3  {'soziale': 91, 'öffentlichen': 79, 'gute': 74...   \n",
       "4  {'deutschen': 54, 'deutsche': 24, 'europäische...   \n",
       "5  {'neue': 78, 'digitale': 50, 'stärker': 50, 'b...   \n",
       "\n",
       "                                 Most common bigrams  \n",
       "0  {'Freie Demokraten': 340, 'Wir Freie': 329, 'D...  \n",
       "1  {'wollen wir': 279, 'Wir wollen': 175, 'in der...  \n",
       "2  {'Wir werden': 167, 'werden wir': 159, 'und di...  \n",
       "3  {'Wir wollen': 318, 'wollen wir': 246, 'in der...  \n",
       "4  {'Die AfD': 107, 'in der': 58, 'für die': 57, ...  \n",
       "5  {'Wir wollen': 266, 'Wir werden': 203, 'wollen...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as JSON.\n",
    "result = df_new.to_json('./export.json', orient='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
